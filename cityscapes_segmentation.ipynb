{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-05-07T05:30:56.80403Z","iopub.status.busy":"2022-05-07T05:30:56.803649Z","iopub.status.idle":"2022-05-07T05:30:56.837939Z","shell.execute_reply":"2022-05-07T05:30:56.836895Z","shell.execute_reply.started":"2022-05-07T05:30:56.803918Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os \n","import torch\n","import torchvision\n","from glob import glob\n","import torch.nn as nn\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","import torchvision.transforms as transform\n","from torch.utils.data import DataLoader,Dataset\n","#from torch.utils.tensorboard import SummaryWriter\n","from torchvision.utils import make_grid\n","\n","#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n","\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-07T05:30:59.733677Z","iopub.status.busy":"2022-05-07T05:30:59.733281Z","iopub.status.idle":"2022-05-07T05:31:00.497937Z","shell.execute_reply":"2022-05-07T05:31:00.49689Z","shell.execute_reply.started":"2022-05-07T05:30:59.733618Z"},"trusted":true},"outputs":[],"source":["train_path = glob('./cityscapes_data/cityscapes_data/train/*')\n","valid_path = glob('./cityscapes_data/cityscapes_data/val/*')\n","\n","fig,ax = plt.subplots(2,2,figsize=(10,10))\n","for i in range(2):\n","    img = plt.imread(train_path[i])\n","    ax[i][0].imshow(img[:,:256])\n","    ax[i][1].imshow(img[:,256:])\n","\n","train_dataset = []\n","validation_dataset = []"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-07T05:31:02.50699Z","iopub.status.busy":"2022-05-07T05:31:02.506222Z","iopub.status.idle":"2022-05-07T05:31:02.520548Z","shell.execute_reply":"2022-05-07T05:31:02.519565Z","shell.execute_reply.started":"2022-05-07T05:31:02.506939Z"},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    \n","    def __init__(self, images_path ,transform_img=None ,transform_label=None):\n","        \n","        self.images_path = images_path\n","        self.transform_img = transform_img\n","        self.transform_label = transform_label\n","\n","    def __len__(self):\n","        return len(self.images_path)\n","\n","    def __getitem__(self, idx):\n","        \n","        img = plt.imread(self.images_path[idx])\n","        image,label = img[:,:int(img.shape[1]/2)],img[:,int(img.shape[1]/2):]\n","    \n","        if self.transform_img:\n","            image = self.transform_img(image)\n","            \n","        if self.transform_label:\n","            label = self.transform_label(label)\n","            \n","        return image, label"]},{"cell_type":"markdown","metadata":{},"source":["### Defining the Transfoms"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-07T05:31:02.523284Z","iopub.status.busy":"2022-05-07T05:31:02.522565Z","iopub.status.idle":"2022-05-07T05:31:02.535883Z","shell.execute_reply":"2022-05-07T05:31:02.534586Z","shell.execute_reply.started":"2022-05-07T05:31:02.523232Z"},"trusted":true},"outputs":[],"source":["mytransformsImage = transform.Compose(\n","    [\n","        transform.ToTensor(),\n","        #transform.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        transform.RandomHorizontalFlip(p=0.9)\n","    ]\n",")\n","mytransformsLabel = transform.Compose(\n","    [\n","        transform.ToTensor(),\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-07T05:31:02.538716Z","iopub.status.busy":"2022-05-07T05:31:02.537999Z","iopub.status.idle":"2022-05-07T05:31:02.547236Z","shell.execute_reply":"2022-05-07T05:31:02.546003Z","shell.execute_reply.started":"2022-05-07T05:31:02.538657Z"},"trusted":true},"outputs":[],"source":["# dataset\n","traindata = MyDataset(train_path, mytransformsImage, mytransformsLabel)\n","valdata = MyDataset(valid_path, mytransformsImage, mytransformsLabel)\n","\n","# Creating the DataLoaders\n","batch_size = 4\n","train_loader = DataLoader(traindata,batch_size)\n","vaild_loader = DataLoader(valdata,1)\n","\n","# inverse_transform = transform.Compose([\n","#     transform.Normalize((-0.485/0.229, -0.456/0.224, -0.406/0.225), (1/0.229, 1/0.224, 1/0.225))\n","# ])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-07T05:31:02.574052Z","iopub.status.busy":"2022-05-07T05:31:02.573611Z","iopub.status.idle":"2022-05-07T05:31:02.588069Z","shell.execute_reply":"2022-05-07T05:31:02.586753Z","shell.execute_reply.started":"2022-05-07T05:31:02.57393Z"},"trusted":true},"outputs":[],"source":["'''\n","    This is a helper function.\n","    This will help in ploting the masked got from the model.\n","\n","'''\n","def show(img,output,label,denorm = False):\n","    img,output,label = img.cpu(),output.cpu(),label.cpu()\n","    fig,ax = plt.subplots(len(output),3,figsize=(10,10))\n","    \n","    for i in range(len(output)):\n","        if(len(output) == 3):\n","            Img,Lab,act = img[i],output[i],label[i]\n","            Img,Lab,act = Img,Lab.detach().permute(1,2,0).numpy(),act\n","            ax[i][0].imshow(Img.permute(1,2,0))\n","            ax[i][1].imshow(Lab)\n","            ax[i][2].imshow(act.permute(1,2,0))\n","        else:\n","            Img,Lab,act = img[i],output[i],label[i]\n","            Img,Lab,act = Img,Lab.detach().permute(1,2,0).numpy(),act\n","            ax[0].imshow(Img.permute(1,2,0))\n","            ax[1].imshow(Lab)\n","            ax[2].imshow(act.permute(1,2,0))\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# UNet"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-07T05:31:02.716647Z","iopub.status.busy":"2022-05-07T05:31:02.71509Z","iopub.status.idle":"2022-05-07T05:31:06.245304Z","shell.execute_reply":"2022-05-07T05:31:06.244077Z","shell.execute_reply.started":"2022-05-07T05:31:02.716584Z"},"trusted":true},"outputs":[],"source":["from models import UNet\n","\n","# initializing the model\n","model_type = 'unet'\n","model = UNet(3).float().to(device)\n","\n","# Parameters, Loss, Optimizer\n","lr = 0.01\n","epochs = 20\n","lossfunc = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-07T05:31:06.283675Z","iopub.status.busy":"2022-05-07T05:31:06.28265Z","iopub.status.idle":"2022-05-07T06:02:21.362291Z","shell.execute_reply":"2022-05-07T06:02:21.361285Z","shell.execute_reply.started":"2022-05-07T05:31:06.283584Z"},"trusted":true},"outputs":[],"source":["train_acc = []\n","val_acc = []\n","train_loss = []\n","val_loss = []\n","\n","for i in range(epochs):\n","    \n","    trainloss = 0\n","    valloss = 0\n","    \n","    for img,label in tqdm(train_loader):\n","        '''\n","            Traning the Model.\n","        '''\n","        optimizer.zero_grad()\n","        img = img.to(device)\n","        label = label.to(device)\n","        output = model(img)\n","        loss = lossfunc(output,label)\n","        loss.backward()\n","        optimizer.step()\n","        trainloss+=loss.item()\n","    \n","    if(i%10==0):\n","        show(img,output,label)\n","\n","    train_loss.append(trainloss/len(train_loader))    \n","  \n","    for img,label in tqdm(vaild_loader):\n","        '''\n","            Validation of Model.\n","        '''\n","        img = img.to(device)\n","        label = label.to(device)\n","        output = model(img)\n","        loss = lossfunc(output,label)\n","        valloss+=loss.item()\n","        \n","    val_loss.append(valloss/len(vaild_loader))  \n","    \n","    print(\"epoch : {} ,train loss : {} ,valid loss : {} \".format(i+1,train_loss[-1],val_loss[-1]))\n","\n","torch.save({\n","    'model' : model.state_dict(),\n","}, './models/{}_{}.pth'.format(model_type))"]},{"cell_type":"markdown","metadata":{},"source":["### Load Checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_type = 'unet'\n","model = UNet(3).float().to(device)\n","\n","chk = torch.load('./models/{}.pth'.format(model_type))\n","model.load_state_dict(chk['model'])"]},{"cell_type":"markdown","metadata":{},"source":["# Ploting & Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-07T06:02:21.365871Z","iopub.status.busy":"2022-05-07T06:02:21.364036Z","iopub.status.idle":"2022-05-07T06:02:21.618552Z","shell.execute_reply":"2022-05-07T06:02:21.61751Z","shell.execute_reply.started":"2022-05-07T06:02:21.365824Z"},"trusted":true},"outputs":[],"source":["plt.plot(train_loss,color='b',label='train loss')\n","plt.plot(val_loss,color='r',label = 'val_loss')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-07T06:19:06.360902Z","iopub.status.busy":"2022-05-07T06:19:06.36056Z","iopub.status.idle":"2022-05-07T06:19:06.374074Z","shell.execute_reply":"2022-05-07T06:19:06.372694Z","shell.execute_reply.started":"2022-05-07T06:19:06.360863Z"},"trusted":true},"outputs":[],"source":["def show(img,output,label,denorm = False):\n","    img,output,label = img.cpu(),output.cpu(),label.cpu()\n","    fig,ax = plt.subplots(len(output),3,figsize=(15,30))\n","    cols = ['Input Image','Actual Output','Predicted Output']\n","    for i in range(len(output)):\n","        if(len(output) == 3):\n","            Img,Lab,act = img[i],output[i],label[i]\n","            Img,Lab,act = Img,Lab.detach().permute(1,2,0).numpy(),act\n","            ax[i][0].imshow(Img.permute(1,2,0))\n","            ax[i][2].imshow(Lab)\n","            ax[i][1].imshow(act.permute(1,2,0))\n","        else:\n","            Img,Lab,act = img[i],output[i],label[i]\n","            Img,Lab,act = Img,Lab.detach().permute(1,2,0).numpy(),act\n","            ax[0].imshow(Img.permute(1,2,0))\n","            ax[2].imshow(Lab)\n","            ax[1].imshow(act.permute(1,2,0))\n","            #ax[0].title('this')\n","            for ax, col in zip(ax, cols):\n","                ax.set_title(col)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-07T06:19:45.467092Z","iopub.status.busy":"2022-05-07T06:19:45.466789Z","iopub.status.idle":"2022-05-07T06:19:58.405542Z","shell.execute_reply":"2022-05-07T06:19:58.404278Z","shell.execute_reply.started":"2022-05-07T06:19:45.467062Z"},"trusted":true},"outputs":[],"source":["c = 0\n","for img,label in (vaild_loader):\n","        img = img.to(device)\n","        label = label.to(device)\n","        output = model(img)\n","        #print(output.shape)\n","        show(img,output,label)\n","        if c>10:\n","            break\n","        c+=1"]},{"cell_type":"markdown","metadata":{},"source":["# Coatnet + Unet "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#from coatnet_seg import CoAtNet"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.15 ('coatnet')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.15"},"vscode":{"interpreter":{"hash":"5666ae4719dbab2063ca1b7ebb1623c9a5532fa1801a2a563feddf5679ae1e85"}}},"nbformat":4,"nbformat_minor":4}
